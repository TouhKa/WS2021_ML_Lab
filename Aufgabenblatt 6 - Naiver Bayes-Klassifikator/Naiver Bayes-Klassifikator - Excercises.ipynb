{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naiver Bayes-Klassifikator\n",
    "\n",
    "\n",
    "Datengrundlage f√ºr die folgende Aufgabenstellung ist der Titanic-Datensatz, unter /Data abgelegt.\n",
    "\n",
    "In dieser Aufgabe sollen Sie einen Klassifikator auf Basis des Bayes-Theorem's selbst implementieren. Wir nehmen f√ºr diese Aufgabe an, dass die einzelnen Merkmale unabh√§ngig voneinander sind. Man spricht in der Literatur von einem naiven Bayes-Klassifikator. Formal l√§sst sich der naive Bayes-Klassifikator wie folgt beschreiben:\n",
    "\n",
    "Gegeben sei ein Merkmalsvektor $\\vec x = (x_1,\\dots, x_n)$  bestehend aus $n$ Merkmalen. Des Weiteren sei $L = \\{C_1,\\dots,C_K\\}$ die Menge von m√∂glichen Klassen. Dann berechnet sich nach Bayes die a posteriori Wahrscheinlichkeit \n",
    "\n",
    "$p(C_k \\vert \\vec{x}) = \\frac{P(C_k) \\ p(\\vec{x} \\vert C_k)}{p(\\vec{x})} \\,$ mit $p(\\vec x) = \\sum_{k\\in L} P(C_k) \\ p(\\vec{x} \\vert C_k) .$\n",
    "\n",
    "Nimmt man an, dass die einzenen Merkmale $x_1,\\dots,x_i$ unabh√§ngig voneinander sind, l√§sst sich die a posteriori Wahrscheinlichkeit wie folgt berechnen:\n",
    "\n",
    "$p(C_k \\vert x_1, \\dots, x_n) = \\frac{P(C_k) \\prod_{i=1}^n p(x_i \\vert C_k)}{p(\\vec x)}$\n",
    "\n",
    "Da $p(x)$ f√ºr ein gegebenen Merkmalsvektor $\\vec x$ konstant ist, und somit die Entscheidung nicht beeinflusst, kann der naive Bayes-Klassifikator wie folgt formuliert werden:\n",
    "\n",
    "$C_y = \\operatorname{argmax}_{k \\in L} P(C_k) \\prod_{i=1}^n p(x_i \\vert C_k)$ \n",
    "\n",
    "\n",
    "Ziel dieser Aufgabe ist einen solchen naiven Bayes-Klassifikator f√ºr die konkrete Anwendung zu implementieren. Idealerweise verwendet man daf√ºr einen gro√üen Datensatz. F√ºr das Verst√§ndnis des Algorithmus erfolgt die Implementierung anhand des bereits bekannten Titanic-Datensatzes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Ziel -> ùê∂ùë¶=argmax p_survived [ (p(Fare|survived))*  (p(Age|survived)) *  (p(Sex|survived)) *  (p(Pclass|survived))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.) Vorbereitungen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv as csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import math\n",
    "%matplotlib inline\n",
    "\n",
    "DATA_FILE = './Data/original_titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_FILE)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Gerne k√∂nnen Sie zum F√ºllen der Datenl√ºcken auch Ihre Implementierung aus den vorherigen Aufgabe einsetzen..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepareData(df):\n",
    "    df.loc[np.isnan(df[\"Age\"]) & (df['Sex']=='female'), 'Age'] = df.loc[df['Sex']=='female', 'Age'].mean()\n",
    "    df.loc[np.isnan(df[\"Age\"]) & (df['Sex']=='male'), 'Age'] = df.loc[df['Sex']=='male', 'Age'].mean()\n",
    "    df.loc[:,'Fare'].interpolate(method='pad', inplace= True) #using existing values to fill NaN values    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepareData(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) A Priori Wahrscheinlichkeiten\n",
    "Bestimmen Sie die A-Priori Wahrscheinlichkeiten $P(C_{survived})$ sowie $P(C_{\\neg survived})$ anhand der Stichprobe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO implement\n",
    "survived = df['Survived'].loc[df['Survived'] == 1]\n",
    "p_survived = survived.count()/len(df)\n",
    "p_not_survived = 1- p_survived\n",
    "\n",
    "print(p_survived, p_not_survived)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) Klassenbedingte Wahrscheinlichkeiten (likelihood)\n",
    "Ziel dieser Aufgabe ist es die klassenbedingten Wahrscheinlichkeiten $p(\\vec{x} \\vert C_k)$ f√ºr die Merkmale *Age, Fare, Sex und Pclass* zu bestimmen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantitative Merkmale\n",
    "Im folgenden sollen die Parameter der normalverteilen Wahrscheinlichkeitsdichtefunktion (WDF) f√ºr die Merkmal *Age* und *Fare* gesch√§tzt werden. \n",
    "\n",
    "Visualisieren Sie zuerst die diskrete klassenbedingte Verteilung des Merkmales *Fare*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.loc[:,'Fare'].isnull().sum())\n",
    "print(df.loc[:,'Pclass'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "survived_ = df.loc[df['Survived']==1, 'Fare']\n",
    "not_survived_ = df.loc[df['Survived']==0,'Fare']\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(survived_, color=\"blue\")\n",
    "plt.hist(not_survived_, color=\"green\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "survived_.plot(kind='density',color=\"red\")\n",
    "not_survived_.plot(kind='density',color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sch√§tzen Sie die Parameter der klassenbedingten Wahrscheinlichkeitsdichtefunktion $p(Fare \\vert C_{survived}),p(Fare \\vert C_{\\neg survived})$ (Maximum-Likelihood Methode). Gehen Sie dabei von einer Normalverteilung aus. Visualisieren Sie die WDFs. Wie bewerten Sie die Trennungswirksamkeit dieses Merkmales?\n",
    "\n",
    "\n",
    "Dichtefunktion:$ \\frac{1}{\\sqrt{2\\pi\\sigma^2}} exp \\{- \\frac{(x-\\mu)^2}{2\\sigma^2} \\} $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#define a generic gaussian function.\n",
    "def gaussian(x, mu, sig):\n",
    "    exponent = math.exp(-(math.pow(x-mu,2)/(2*sig)))\n",
    "    return (1/(math.sqrt(2*math.pi)*sig))*exponent\n",
    "\n",
    "def pFareSurvived(fare):  \n",
    "    survived_ = df.loc[df['Survived']==1, 'Fare']\n",
    "    survived_mean = np.mean(np.array(survived_))\n",
    "    survived_var = np.var(np.array(survived_))\n",
    "    return gaussian(fare,survived_mean, survived_var)\n",
    "\n",
    "def pFareNotSurvived(fare):\n",
    "    not_survived_ = df.loc[df['Survived']==0,'Fare']\n",
    "    not_survived_mean = np.mean(np.array(not_survived_))\n",
    "    not_survived_var = np.var(np.array(not_survived_))\n",
    "    return gaussian(fare,not_survived_mean, not_survived_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_surv = []\n",
    "g_not_surv = []\n",
    "for x in df.loc[df['Survived']==1, 'Fare']:\n",
    "    g_surv.append(pFareSurvived(x))\n",
    "    \n",
    "for x in df.loc[df['Survived']==0, 'Fare']:\n",
    "    g_not_surv.append(pFareNotSurvived(x))\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(g_not_surv,color=\"green\")\n",
    "plt.hist(g_surv, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sch√§tzen Sie analog die Parameter der klassenbedingten Wahrscheinlichkeitsdichtefunktion $p(Age \\vert C_{survived}),p(Age \\vert C_{\\neg survived})$ (Maximum-Likelihood Methode). Gehen Sie auch hier von einer Normalverteilung aus. Visualisieren Sie die WDFs. Wie bewerten Sie die Trennungswirksamkeit dieses Merkmales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pAgeSurvived(age): \n",
    "    survived_ = df.loc[df['Survived']==1, 'Age']\n",
    "    survived_mean = np.mean(np.array(survived_))\n",
    "    survived_var = np.var(np.array(survived_))\n",
    "    return gaussian(age,survived_mean, survived_var)\n",
    " \n",
    "def pAgeNotSurvived(age):    \n",
    "    not_survived_ = df.loc[df['Survived']==0,'Age']\n",
    "    not_survived_mean = np.mean(np.array(not_survived_))\n",
    "    not_survived_var = np.var(np.array(not_survived_))\n",
    "    return gaussian(age, not_survived_mean, not_survived_var)\n",
    "# TODO print und max-likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_surv = []\n",
    "g_not_surv = []\n",
    "for x in df.loc[df['Survived']==1, 'Age']:\n",
    "    g_surv.append(pAgeSurvived(x))\n",
    "    \n",
    "for x in df.loc[df['Survived']==0, 'Age']:\n",
    "    g_not_surv.append(pAgeNotSurvived(x))\n",
    "    \n",
    "\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.hist(g_not_surv,color=\"green\")\n",
    "plt.hist(g_surv, color=\"red\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Kategoriale Merkmale\n",
    "In dem vorliegenden Datensatz sind einige kategoriale (qualitative) Merkmale enthalten. Da die klassenbedingten Wahrscheinlichkeiten f√ºr diese Merkmale nicht mit kontinuierlichen Dichtefunktionen gesch√§tzt werden k√∂nnen, wird die relative H√§ufigkeit eingesetzt.\n",
    "\n",
    "\n",
    "Visualisieren sie die absolute H√§ufigkeiten f√ºr das Merkmal *Pclass* f√ºr die Klassenzugeh√∂rigkeit *Survived* und *Not Survived*. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,5))\n",
    "class_one = np.array(df.loc[df['Pclass']==1, 'Survived'])\n",
    "class_two = np.array(df.loc[df['Pclass']==2, 'Survived'])\n",
    "class_three = np.array(df.loc[df['Pclass']==3, 'Survived'])\n",
    "classes = [1,2,3]\n",
    "classes_count_survived = [len(np.where(class_one == 1)[0]),len(np.where(class_two == 1)[0]), len(np.where(class_three == 1)[0])]\n",
    "classes_count_not_survived = [len(np.where(class_one == 0)[0]),len(np.where(class_two == 0)[0]), len(np.where(class_three == 0)[0])]\n",
    "\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, sharey=True)\n",
    "ax1.bar(classes, classes_count_not_survived, color = \"red\" )\n",
    "ax1.set_xticks(classes)\n",
    "ax1.set_xlabel(\"Classes\")\n",
    "ax1.set_ylabel(\"relative frequency\")\n",
    "ax1.set_title(\"Pclass-> Not Survived\")\n",
    "\n",
    "ax2.bar(classes, classes_count_survived, color= \"blue\" )\n",
    "ax2.set_xticks(classes)\n",
    "ax2.set_xlabel(\"Classes\")\n",
    "ax2.set_ylabel(\"relative frequency\")\n",
    "ax2.set_title(\"Pclass-> Survived\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestimmen Sie die klassenbedingten Wahrscheinlichkeiten $p(Pclass \\vert C_{survived}),p(Pclass \\vert C_{\\neg survived})$ anhand der entsprechenden relativen H√§ufigkeiten und geben Sie das Ergebniss aus. Wie bewerten Sie die Trennungswirksamkeit dieses Merkmales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def pPClassSurvived(x):\n",
    "    tmp = np.array(df.loc[df['Survived']==1, 'Pclass'])\n",
    "    return len(np.where(tmp == x)[0]) / len(tmp)\n",
    "\n",
    "def pPClassNotSurvived(x):\n",
    "    tmp = np.array(df.loc[df['Survived']==0, 'Pclass'])\n",
    "    return len(np.where(tmp == x)[0]) / len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pc in (1,2,3):\n",
    "    print(\"class %d:  p(Pclass|surv): %f\\tp(Pclass|notSurv): %f\" % (pc,pPClassSurvived(pc),pPClassNotSurvived(pc)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bestimmen sie analog die klassenbedingten Wahrscheinlichkeiten $p(Sex \\vert C_{survived}),p(Sex \\vert C_{\\neg survived})$. Wie bewerten Sie die Trennungswirksamkeit dieses Merkmales?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pSexSurvived(x):\n",
    "    tmp = np.array(df.loc[df['Survived']==1, 'Sex'])\n",
    "    return len(np.where(tmp == x)[0]) / len(tmp)\n",
    "\n",
    "def pSexNotSurvived(x):\n",
    "    tmp = np.array(df.loc[df['Survived']==0, 'Sex'])\n",
    "    return len(np.where(tmp == x)[0]) / len(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s in (\"male\", \"female\"):\n",
    "    print(\"Sex %s:  p(Sex|surv): %f\\tp(Sex|notSurv): %f\" % (s,pSexSurvived(s),pSexNotSurvived(s)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) Klassifikator implementieren\n",
    "\n",
    "F√ºgen Sie nun alle Bestandteile f√ºr den naiven Bayes-Klassifikator zusammen. Berechnen Sie zuerst die a posteriori Wahrscheinlichkeiten $p(C_k \\vert x_1, \\dots, x_n) = \\frac{P(C_k) \\prod_{i=1}^n p(x_i \\vert C_k)}{p(\\vec x)}$ f√ºr die beiden Klassen. Geben Sie die Ergebnisse f√ºr einen exemplarischen Merkmalsvektor $\\vec x = (x_1,\\dots, x_n)$ aus. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#example feature vector. \n",
    "x=dict(age=25,sex='female',pclass=1,fare=100)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numeratorPosteriorSurvived(x):\n",
    "    return pFareSurvived(x['fare']), pAgeSurvived(x['age']),pPClassSurvived(x['pclass']), pSexSurvived(x['sex'])\n",
    "\n",
    "def numeratorPosteriorNotSurvived(x):\n",
    "    return pFareNotSurvived(x['fare']), pAgeNotSurvived(x['age']), pPClassNotSurvived(x['pclass']), pSexNotSurvived(x['sex'])\n",
    "\n",
    "#the evidence is the dominator p(x) of the posterior\n",
    "def evidence(x):\n",
    "    return 1.\n",
    "    \n",
    "def posteriorSurvived(x): \n",
    "    probabilities = 1.\n",
    "    fare, age, pclass, sex = numeratorPosteriorSurvived(x)\n",
    "#     print(fare, age, pclass, sex)\n",
    "    probabilities *= fare\n",
    "    probabilities *= age\n",
    "    probabilities *= pclass \n",
    "    probabilities *= sex\n",
    "    probabilities *= p_survived\n",
    "    \n",
    "    return probabilities/evidence(x)\n",
    "                  \n",
    "    \n",
    "def posteriorNotSurvived(x):\n",
    "    probabilities = 1.\n",
    "    fare, age, pclass, sex = numeratorPosteriorNotSurvived(x)\n",
    "#     print(fare, age, pclass, sex)\n",
    "    probabilities *= fare\n",
    "    probabilities *= age\n",
    "    probabilities *= pclass \n",
    "    probabilities *= sex\n",
    "    probabilities *= p_survived\n",
    "    \n",
    "    return probabilities/evidence(x)\n",
    "                  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print (\"p(survived|x) = %f\\n\" % (posteriorSurvived(x) ))\n",
    "print (\"p(notSurvived|x) = %f \" % (posteriorNotSurvived(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Da $p(\\vec x)$ f√ºr ein gegebenen Merkmalsvektor $\\vec x$ konstant ist und somit die Entscheidung nicht beeinflusst muss $p(\\vec x)$ f√ºr die finale Klassifikation nicht berechnet werden. Des weiteren wird aus nummerischen Gr√ºnden typischerweise der Logarithmus der Wahrscheinlichkeiten eingesetzt (https://en.wikipedia.org/wiki/Log_probability).\n",
    "\n",
    "Der naive Bayes-Klassifikator l√§st sich somit auch wie folgt formulieren:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{aligned}\n",
    "C_y &= \\operatorname{argmax}_{k \\in L} \\log{( P(C_k) \\prod_{i=1}^n p(x_i \\vert C_k))} \\\\\n",
    "    &= \\operatorname{argmax}_{k \\in L}  \\log{P(C_k)} + \\sum_{i=1}^n \\log{p(x_i \\vert C_k)}\n",
    "\\end{aligned}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Implementieren und testen Sie die entsprechende Entscheidungsfunktion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def logPosteriorSurvived(x):      \n",
    "    log_ck = math.log(p_survived)\n",
    "    log_ci_cK = math.log( np.sum(numeratorPosteriorSurvived(x)) )\n",
    "    return log_ck + log_ci_cK\n",
    "    \n",
    "def logPosteriorNotSurvived(x):   \n",
    "    log_ck = math.log(p_not_survived)\n",
    "    log_ci_cK = math.log( np.sum(numeratorPosteriorNotSurvived(x)) )\n",
    "    return log_ck + log_ci_cK\n",
    "    \n",
    "def predict(x):\n",
    "    log_survived = logPosteriorSurvived(x)\n",
    "    log_not_survived = logPosteriorNotSurvived(x)\n",
    "    return np.argmax([log_not_survived, log_survived]) # reihenfolge entscheidet, weil index zur√ºckgegeben wird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenden Sie den von Ihnen implementierten Algorithmus auf den Datensatz an und ermitteln Sie die Korrektklassifizierungsrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_true = []\n",
    "labels_pred = []\n",
    "tp = 0\n",
    "fp = 0\n",
    "tn = 0\n",
    "fn = 0\n",
    "for idx, row_vals in enumerate(df.loc[:, ['Age', 'Fare', 'Pclass', 'Sex', 'Survived']].values):\n",
    "\n",
    "    labels_true.append(row_vals[-1])\n",
    "    x = dict(age=row_vals[0],sex=row_vals[2],pclass=row_vals[2],fare=row_vals[1])\n",
    "    y =predict(x)\n",
    "    #print(idx, y)\n",
    "    labels_pred.append(y)\n",
    "    \n",
    "\n",
    "for idx, label in enumerate(labels_true):\n",
    "    if label == labels_pred[idx]:\n",
    "        if label == 1:\n",
    "             tp += 1\n",
    "        else:\n",
    "            tn += 1\n",
    "    else:\n",
    "        if label == 1:\n",
    "            fn += 1          \n",
    "        else:\n",
    "            fp += 1\n",
    "print(\"True Positives: %d\" %tp)   \n",
    "print(\"True Negatives: %d\" %tn)\n",
    "\n",
    "print(\"False Positives: %d\" %fp)\n",
    "print(\"False Negatives: %d\" %fn)\n",
    "\n",
    "if (tp + tn + fp + fn) > 0:\n",
    "    acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "    print(\"Accurency: %f\" %acc) "
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
