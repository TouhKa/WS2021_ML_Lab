{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross-Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation mit Cross-Validation\n",
    "Um verschiede Verfahren und Parameter möglichst ohne die Gefahr des overfitting evaluieren zu können, steht man immer vor dem Problem: Mit welchen Daten trainiere ich meine Verfahren und mit welchen teste ich? Offensichtlich hängt das Ergebnis der Evaluation stark von der konkreten Auswahl des Test- bzw. Trainingsdatensatzes ab. \n",
    "\n",
    "Eine in der Literatur etablierte Methode der systematischen Evaluation ist Cross-Validation (Link: [Cross-Validation](https://en.wikipedia.org/wiki/Cross-validation_%28statistics%29)). Die grundlegende Idee des k-Fold  Cross-Validation (Link: [k-fold cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)\\#k-fold_cross-validation)) ist wie folgt: Die Gesamtmenge an Klassen-annotierten Datensätzen $T$ wird zufällig in $k$ gleich große Teilmengen (Folds) $T_1 \\dots T_k$ aufgeteilt. Es werden $k$ Testiteration $i_1 \\dots i_k$ durchgeführt. In jeder Iteration wird jeweils eine andere Teilmenge $T_i$ als Testdatensatz und die restlichen Daten $T \\setminus T_i$ als Trainingsdatensatz verwendet. Als Gesamt Ergebniss der Cross-Validation wird der Mittelwert der Genauigkeiten der einzelnen Iteration herangezogen. \n",
    "\n",
    "Weitere Verfahren sind bspw. Holdout (Link: [Holdout](https://en.wikipedia.org/wiki/Cross-validation_(statistics)\\#Holdout_method)), Nested cross-validation (Link: [Nested cross-validation](https://en.wikipedia.org/wiki/Cross-validation_(statistics)\\#Nested_cross-validation)) etc.\n",
    "\n",
    "<figure>\n",
    "<img src=\"./Figures/k-fold-cross-validation.png\" alt=\"drawing\" style=\"width:600px;\">\n",
    "    <figcaption>k-fold Cross Validation, Quelle: https://upload.wikimedia.org/wikipedia/commons/thumb/b/b5/K-fold_cross_validation_EN.svg/500px-K-fold_cross_validation_EN.svg.png\n",
    "        </figcaption>\n",
    "</figure>\n",
    "\n",
    "Erweitern Sie Ihre Implementierung des KNN-Algorithmus aus dem vorherigen Teil um das <b>k-fold Cross-Validation</b> Verfahren. Wählen Sie hierbei einen geeigneten Wert für die Anzahl der k-folds, bzw. experimentieren Sie mit verschiedenen Werte."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv as csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# k =5 ist der sklearn default wert\n",
    "class KFold():\n",
    "    df = None\n",
    "    fold_len = 0\n",
    "    k = 5\n",
    "    cols_to_normalize = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "    acc = []\n",
    "    start = 0\n",
    "    end = 0\n",
    "    fold_old = pd.DataFrame()\n",
    "    \n",
    "    def __init__(self, df, k=5):\n",
    "        self.df = df\n",
    "        self.k = k\n",
    "        self.fold_len= int(round(len(df)/self.k, 0))\n",
    "        print(\"Lenght of Dataframe: {}\\nFold Lenght: {}\".format(len(self.df), self.fold_len))\n",
    "        \n",
    "    def run_iteartion(self):\n",
    "        for i in range(self.k): \n",
    "            self.end += self.fold_len\n",
    "            print(\"\\nStart: {} End: {}\".format(self.start, self.end))\n",
    "            \n",
    "\n",
    "            df_train = self.df.loc[(self.end+1) : , :]\n",
    "            df_train = df_train.append(self.fold_old, ignore_index = True)\n",
    "            \n",
    "            df_test  = self.df.loc[self.start : self.end, :]\n",
    "\n",
    "\n",
    "            #important: rest index for normalizeation\n",
    "            df_train_norm = normalize(df_train, self.cols_to_normalize) \n",
    "            df_test_norm = normalize(df_test.reset_index(), self.cols_to_normalize)\n",
    "\n",
    "       \n",
    "            #run training\n",
    "            self.acc.append(train_test_iteration(df_train_norm, df_test_norm))\n",
    "            self.start = self.end + 1\n",
    "            self.fold_old =  self.fold_old.append(df_test, ignore_index = True)\n",
    "\n",
    "\n",
    "    def getAcc(self):\n",
    "        return self.acc\n",
    "    \n",
    "    def getMeanAcc(self):\n",
    "        return np.array(self.acc).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df, cols):\n",
    "    \n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    for col_name in cols:\n",
    "        u = np.mean(df_normalized.loc[:,col_name])\n",
    "        var = np.var(df_normalized.loc[:, col_name])\n",
    "        o = np.sqrt(var)\n",
    "        #print(\"{}:\\n---\\nMittelwert: {}\\nVarianz: {}\\nStandartabweichung: {}\".format(col_name, u, var, o))\n",
    "\n",
    "        for idx, val in enumerate(df_normalized.loc[:,col_name]):           \n",
    "            df_normalized.loc[idx, col_name] =  (val - u )/o\n",
    "    \n",
    "    return df_normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatureVector(row):\n",
    "    # TODO : implement\n",
    "    cl = float(row.loc['Pclass'])\n",
    "    s = 0.0\n",
    "    if row.loc['Sex'] == 'female': \n",
    "        s = 1.0\n",
    "    x = np.array((float(row.loc['Age']),cl, s, row.loc['Fare'])).reshape(-1, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(object):\n",
    "    trainLabel = None\n",
    "    trainLabel = None\n",
    "    k = 1\n",
    "    distances = []\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    def distance(self, vector1, vector2 ):\n",
    "        p = 1\n",
    "        return sum(abs(e1-e2)**p for e1, e2 in zip(vector1, vector2))**(1/p)\n",
    "    \n",
    "    \n",
    "    def fit(self, data, label):\n",
    "        self.trainData = data\n",
    "        self.trainLabel = label\n",
    "       \n",
    "        \n",
    "\n",
    "    def predict(self, x):\n",
    "        for idx, trainSample in enumerate(self.trainData):\n",
    "            dist = self.distance(trainSample, x)\n",
    "            self.distances.append((trainSample, dist, self.trainLabel[idx]))\n",
    "        self.distances.sort(key= lambda x: x[1]) #sort for minimal distance\n",
    "        return self.distances[:self.k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_iteration(df_train_norm, df_test_norm):\n",
    "    data = []\n",
    "    labels = []\n",
    "    l_train = len(df_train_norm)\n",
    "    i = 0\n",
    "    tp = 0\n",
    "    fp = 0\n",
    "    fn = 0\n",
    "    tn = 0\n",
    "    \n",
    "    while i < l_train:\n",
    "   \n",
    "        data.append(extractFeatureVector(df_train_norm.iloc[i]))\n",
    "        labels.append(df_train_norm.loc[i, 'Survived'])\n",
    "        i += 1\n",
    "    train_data = np.array(data)\n",
    "    train_label = np.array(labels)\n",
    "\n",
    "    knn = KNN(3)\n",
    "    knn.fit(train_data, train_label)\n",
    "    l_test = len(df_test_norm)\n",
    "\n",
    "    i = 0\n",
    "    while i < l_test:\n",
    "        row = df_test_norm.iloc[i]\n",
    "        label = int(df_test_norm.loc[i, 'Survived'])\n",
    "        sortedNeighbors = knn.predict(extractFeatureVector(row))\n",
    "\n",
    "\n",
    "        for neighbor in sortedNeighbors:\n",
    "            if label ==  neighbor[2]:\n",
    "                if label == 1:\n",
    "                    tp +=1\n",
    "                else:\n",
    "                    tn += 1\n",
    "\n",
    "            else: \n",
    "                if label == 1:\n",
    "                    fn +=1\n",
    "                else:\n",
    "                    fp += 1\n",
    "        i+=1\n",
    "    #get acc           \n",
    "    print(\"True Positives: %d\" %tp)   \n",
    "    print(\"True Negatives: %d\" %tn)\n",
    "\n",
    "    print(\"False Positives: %d\" %fp)\n",
    "    print(\"False Negatives: %d\\n\" %fn)\n",
    "\n",
    "    return (tp + tn) / (tp + tn + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lenght of Dataframe: 1309\n",
      "Fold Lenght: 262\n",
      "\n",
      "Start: 0 End: 262\n",
      "True Positives: 0\n",
      "True Negatives: 462\n",
      "False Positives: 0\n",
      "False Negatives: 327\n",
      "\n",
      "\n",
      "Start: 263 End: 524\n",
      "True Positives: 0\n",
      "True Negatives: 495\n",
      "False Positives: 0\n",
      "False Negatives: 291\n",
      "\n",
      "\n",
      "Start: 525 End: 786\n",
      "True Positives: 0\n",
      "True Negatives: 492\n",
      "False Positives: 0\n",
      "False Negatives: 294\n",
      "\n",
      "\n",
      "Start: 787 End: 1048\n",
      "True Positives: 0\n",
      "True Negatives: 504\n",
      "False Positives: 0\n",
      "False Negatives: 282\n",
      "\n",
      "\n",
      "Start: 1049 End: 1310\n",
      "True Positives: 0\n",
      "True Negatives: 474\n",
      "False Positives: 0\n",
      "False Negatives: 306\n",
      "\n",
      "[0.5855513307984791, 0.6297709923664122, 0.6259541984732825, 0.6412213740458015, 0.6076923076923076]\n"
     ]
    }
   ],
   "source": [
    "# TODO: implement\n",
    "DATA_FILE = './Data/original_titanic.csv'\n",
    "df_original = pd.read_csv(DATA_FILE)\n",
    "\n",
    "# (1) Datenlücken interpolieren\n",
    "def prepareData(df):\n",
    "    df.loc[np.isnan(df[\"Age\"]) & (df['Sex']=='female'), 'Age'] = df.loc[df['Sex']=='female', 'Age'].mean()\n",
    "    df.loc[np.isnan(df[\"Age\"]) & (df['Sex']=='male'), 'Age'] = df.loc[df['Sex']=='male', 'Age'].mean()\n",
    "    df.loc[:,'Fare'].interpolate(method='pad', inplace= True) #using existing values to fill NaN values\n",
    "    return df\n",
    "\n",
    "df_prepared = prepareData(df_original)\n",
    "\n",
    "\n",
    "# # (2) Datensatz stochastisch verändern\n",
    "df_shuffled =  df_prepared.sample(frac = 1).reset_index(drop=True) \n",
    "\n",
    "# # (3) Aufteilung in Trnings- und Testdatensatz\n",
    "# # (4) run trainings iteration for each fold\n",
    "kfold = KFold(df_shuffled)\n",
    "\n",
    "kfold.run_iteartion()\n",
    "print(kfold.getAcc())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6180380406752566\n"
     ]
    }
   ],
   "source": [
    "# # (5) get mean Acc\n",
    "acc = np.array(kfold.getAcc())\n",
    "mean_acc = acc.mean(dtype=np.float64)\n",
    "print(mean_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
