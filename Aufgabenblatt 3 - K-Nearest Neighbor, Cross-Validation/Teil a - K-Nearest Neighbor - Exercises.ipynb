{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Nearest Neighbor (KNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ziel der vorliegenden Aufgabe ist es einen KNN-Kassifikator zu implementieren und auf den Titanic Datensatz anzuwenden. Dabei sollen Sie insbesondere untersuchen welcher Merkmalsraum und welches Ähnlichkeitsmaß für diese Aufgabe geeignet ist. \n",
    "\n",
    "Der KNN-Klassifikator ist eine einfache, parameterfreie Methode, bei welcher zu jedem Testvektor $\\vec x_q$ die $k$-nächsten-Nachbarn, $\\{\\vec {x_t^1}...\\vec {x_t^k}\\}$ im Trainingsbestand, unter Berücksichtigung eines frei zu definierenden Ähnlichkeitsmaß, ermittelt werden. Die Klassenzugehörigkeit wird über einen einfachen Mehrheitsentscheid der nächsten $k$-Nachbarn für $\\vec x_q$ prädiziert (siehe auch https://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv as csv\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten einlesen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId       0\n",
      "Survived          0\n",
      "Pclass            0\n",
      "Name              0\n",
      "Sex               0\n",
      "Age             263\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Ticket            0\n",
      "Fare              1\n",
      "Cabin          1014\n",
      "Embarked          2\n",
      "Home-Dest       564\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "DATA_FILE = './Data/original_titanic.csv'\n",
    "df_original = pd.read_csv(DATA_FILE)\n",
    "#identify columns with NaN values\n",
    "print(df_original.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vorbereitungen\n",
    "\n",
    "Führen Sie hier folgende Bearbeitungsschritte durch:\n",
    "* (1) Datenlücken interpolieren,\n",
    "* (2) Datensatz stochastisch verändern, \n",
    "* (3) Aufteilung in Trainings- und Testdatensatz.\n",
    "\n",
    "Sie können Ihre Implementierungen der vorherigen Arbeitsblätter nutzen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PassengerId       0\n",
      "Survived          0\n",
      "Pclass            0\n",
      "Name              0\n",
      "Sex               0\n",
      "Age               0\n",
      "SibSp             0\n",
      "Parch             0\n",
      "Ticket            0\n",
      "Fare              0\n",
      "Cabin          1014\n",
      "Embarked          2\n",
      "Home-Dest       564\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# (1) Datenlücken interpolieren\n",
    "def prepareData(df):\n",
    "    df.loc[np.isnan(df[\"Age\"]) & (df['Sex']=='female'), 'Age'] = df.loc[df['Sex']=='female', 'Age'].mean()\n",
    "    df.loc[np.isnan(df[\"Age\"]) & (df['Sex']=='male'), 'Age'] = df.loc[df['Sex']=='male', 'Age'].mean()\n",
    "    df.loc[:,'Fare'].interpolate(method='pad', inplace= True) #using existing values to fill NaN values\n",
    "    return df\n",
    "df_prepared = prepareData(df_original)\n",
    "print(df_prepared.isna().sum())\n",
    "\n",
    "# (2) Datensatz stochastisch verändern\n",
    "df_shuffled =  df_prepared.sample(frac = 1).reset_index(drop=True) \n",
    "\n",
    "# (3) Aufteilung in Trainings- und Testdatensatz\n",
    "len_all = len(df_shuffled)\n",
    "len_train = round(len_all * 0.8, 0)\n",
    "len_test = round(len_all * 0.2, 0)\n",
    "\n",
    "df_train = df_shuffled[: int(len_train)]\n",
    "df_test  = df_shuffled[: int(len_test)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merkmale standardisieren\n",
    "Die <i>Standardisierung</i> verleiht den Daten die Eigenschaften einer Standardnormalverteilung. Der Mittelwert jeder Merkmalsspalte beträgt 0, die Standardabweichung jeder Merkmalsspalte beträgt 1. Um zum Beispiel das Merkmal j zu standardiesieren, wird der Mittelwert $\\mu$ der jeweiligen Stichprobe abgezogen und das Ergebnis durch die Standardabweichung $\\sigma$ dividiert. Das Standardisierungsverfahren wird auf die Merkmalsspalten der Datenmenge einzeln angewendet. Siehe auch: https://en.wikipedia.org/wiki/Standard_score <br>\n",
    "\n",
    "$x_j^{\\prime(i)} = \\frac{x_j^{(i)} - \\mu_j}{\\sigma_j}$. \n",
    "\n",
    "Implementieren sie die Funktion <b>normalize()</b> welche die Standardisierung (anhand Mittelwert und Standardabweichung) des Trainingsdatensatzes durchführt. Die Methoden-Parameter können Sie entsprechend Ihrer Implementierung erweitern. Überlegen Sie sich hierbei, welche Merkmale zur Standardisierung geeignet sind und welche nicht. Sie können Ihre Implementierung testen, indem Sie die Werte Mittelwert und Standardabweichung Ihrer standardisierten Merkmalsspalten prüfen. Der Mittelwert sollte 0 sein, die Standardabweichung 1. Geben Sie die Werte aus.\n",
    "\n",
    "Speichern Sie sich hierbei die Werte für Mittelwert und Standardabweichung des Trainingsdatensatzes in einer geeigneten Datenstruktur. Führen sie die Standardisierung des Testdatensatzes anhand der Werte von Mittelwert und Standardabweichung vom Trainingsdatensatzes durch. <br>\n",
    "\n",
    "<b>Wichtiger Hinweis</b>: Implementieren Sie die Funktion eigenständig, eine Standard-Funktion aus einem Framework ist nicht zulässig, wie bspw. *sklearn.preprocessing.StandardScaler*. Zum Testen Ihrer Implementierung können Sie diese Funktion nutzen. Standard-Numpy-Funktion zur Berechnung von *Mittelwert* und *Standardabweichung* sind selbstverständlich zugelassen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "Age:\n",
      "---\n",
      "Mittelwert: 29.945576613782617\n",
      "Varianz: 162.3745813822387\n",
      "Standartabweichung: 12.742628511505728\n",
      "Mittelwert' : 0.0\n",
      "Varianz' : 1.0\n",
      "Standartabweichung' : 1.0\n",
      "\n",
      "SibSp:\n",
      "---\n",
      "Mittelwert: 0.49570200573065903\n",
      "Varianz: 1.13441323689187\n",
      "Standartabweichung: 1.0650883704612824\n",
      "Mittelwert' : 0.0\n",
      "Varianz' : 1.0\n",
      "Standartabweichung' : 1.0\n",
      "\n",
      "Parch:\n",
      "---\n",
      "Mittelwert: 0.384909264565425\n",
      "Varianz: 0.7907178284432986\n",
      "Standartabweichung: 0.8892231600916042\n",
      "Mittelwert' : 0.0\n",
      "Varianz' : 0.9999999999999998\n",
      "Standartabweichung' : 0.9999999999999999\n",
      "\n",
      "Fare:\n",
      "---\n",
      "Mittelwert: 32.896748137535816\n",
      "Varianz: 2569.379393477339\n",
      "Standartabweichung: 50.689046089636946\n",
      "Mittelwert' : 0.0\n",
      "Varianz' : 1.0000000000000004\n",
      "Standartabweichung' : 1.0000000000000002\n",
      "\n",
      "\n",
      "-------------------------------\n",
      "\n",
      "Test:\n",
      "Age:\n",
      "---\n",
      "Mittelwert: 30.660582002464718\n",
      "Varianz: 157.95146912836128\n",
      "Standartabweichung: 12.567874487293437\n",
      "Mittelwert' : 0.0\n",
      "Varianz' : 1.0\n",
      "Standartabweichung' : 1.0\n",
      "\n",
      "SibSp:\n",
      "---\n",
      "Mittelwert: 0.583969465648855\n",
      "Varianz: 1.50249111357147\n",
      "Standartabweichung: 1.2257614423579615\n",
      "Mittelwert' : 0.0\n",
      "Varianz' : 0.9999999999999998\n",
      "Standartabweichung' : 0.9999999999999999\n",
      "\n",
      "Parch:\n",
      "---\n",
      "Mittelwert: 0.3511450381679389\n",
      "Varianz: 0.6018880018646932\n",
      "Standartabweichung: 0.775814411998574\n",
      "Mittelwert' : 0.0\n",
      "Varianz' : 1.0\n",
      "Standartabweichung' : 1.0\n",
      "\n",
      "Fare:\n",
      "---\n",
      "Mittelwert: 30.21397786259542\n",
      "Varianz: 1788.7444817214948\n",
      "Standartabweichung: 42.293551301841454\n",
      "Mittelwert' : 0.0\n",
      "Varianz' : 0.9999999999999998\n",
      "Standartabweichung' : 0.9999999999999999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def normalize(df, cols):\n",
    "    df_normalized = df.copy()\n",
    "    \n",
    "    for col_name in cols:\n",
    "        \n",
    "        #u = df_normalized.loc[:,col_name].mean()\n",
    "        u = np.mean(df_normalized.loc[:,col_name])\n",
    "        var = np.var(df_normalized.loc[:, col_name])\n",
    "        o = np.sqrt(var)\n",
    "        print(\"{}:\\n---\\nMittelwert: {}\\nVarianz: {}\\nStandartabweichung: {}\".format(col_name, u, var, o))\n",
    "\n",
    "        for idx, val in enumerate(df_normalized.loc[:,col_name]):           \n",
    "            df_normalized.loc[idx, col_name] =  (val - u )/o\n",
    "\n",
    "        u_strich = 1/o*(u-u) # siehe wikipedia\n",
    "        var_strich = np.var(df_normalized[col_name])\n",
    "        o_strich = np.sqrt(var_strich)\n",
    "        print(\"Mittelwert' : {}\\nVarianz' : {}\\nStandartabweichung' : {}\\n\".format(u_strich, var_strich, o_strich))\n",
    "    return df_normalized\n",
    "\n",
    "\n",
    "\n",
    "#kategorisch-ordinale Merkmale: Age, SibSp, parch \n",
    "#quantitative merkmale: Fare\n",
    "cols_to_normalize = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "print(\"Train:\")\n",
    "df_train_norm = normalize(df_train, cols_to_normalize)  \n",
    "\n",
    "print(\"\\n-------------------------------\\n\")\n",
    "print(\"Test:\")\n",
    "df_test_norm = normalize(df_test, cols_to_normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.preprocessing import StandardScaler\n",
    "# def test_normalize(df, cols):\n",
    "#     for col_name in cols:\n",
    "#         scaler = StandardScaler()\n",
    "#         scaler.fit(np.array(df[col_name]).reshape(-1, 1))\n",
    "#         u = scaler.mean_\n",
    "#         var = scaler.var_\n",
    "#         o = np.sqrt(var)\n",
    "#         print(\"{}:\\n---\\nMittelwert: {}\\nVarianz: {}\\nStandartabweichung: {}\\n\".format(col_name, u, var, o))\n",
    "\n",
    "# test_normalize(df_train, cols_to_normalize)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merkmalsraum definieren\n",
    "Unabhängig von der eingesetzten Methodik zur Klassifikation ist es wichtig, dass Sie sich Gedanken über den Merkmalsraum machen. Konkret bedeutet das, dass sie definieren müssen wie ein Merkmalsvektor aussieht und mit welchem Ähnlichkeitsmaß Merkmalsvektoren verglichen werden. Sie sollten sich dabei mit den folgenden Fragen auseinander setzen:\n",
    "* Welche einzelnen Attribute aus einem Objekt des Datensatzes sollen verwendet werden?\n",
    "* Welche Probleme ergeben sich aufgrund von unterschiedlichen Skalenniveaus der Attribute? Wie können Sie diesen begegnen? \n",
    "* Wie gehen Sie mit kategoriellen Merkmalen um?\n",
    "* Welches Ähnlichkeitsmaß setzen Sie ein? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merkmalsraum definieren- Antwort\n",
    "Welche einzelnen Attribute aus einem Objekt des Datensatzes sollen verwendet werden?\n",
    "* Age, PClass, Sex, ggf. Fare\n",
    "\n",
    "Welche Probleme ergeben sich aufgrund von unterschiedlichen Skalenniveaus der Attribute? Wie können Sie diesen begegnen? \n",
    "* Bspw. Fare und Age haben größere werte als Parch und SibSp. \n",
    "* TODO\n",
    "\n",
    "Wie gehen Sie mit kategoriellen Merkmalen um?\n",
    "* Darunter sind 2 kategorische Werte. Diese können auf numerische Werte übertragen werden. Bspw. Female = 0, Male = 1\n",
    "\n",
    "Welches Ähnlichkeitsmaß setzen Sie ein? \n",
    "* Euklidische Distanz-> \"Luftlinie\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merkmalsvektor extrahieren und normalisieren bzw. standardisieren\n",
    "Schreiben sie eine Methode welche aus einer gegebenen Datenreihe einen Merkmalsvektor extrahiert. D.h. der Input ist eine Reihe aus dem Datensatz, der Rückgabewert ein Vektor bestehend aus den Daten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFeatureVector(row):\n",
    "    # TODO : implement\n",
    "    cl = float(row.loc['Pclass'])\n",
    "    s = 0.0\n",
    "    if row.loc['Sex'] == 'female': \n",
    "        s = 1.0\n",
    "    x = np.array((float(row.loc['Age']),cl, s, row.loc['Fare'])).reshape(-1, 1)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testen Sie die Funktion auf einem beliebigen Objekt des Datensatzes. Überprüfen Sie ob das Resultat Ihren Erwartungen entspricht. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.6522826]\n",
      " [ 3.       ]\n",
      " [ 0.       ]\n",
      " [-0.5098251]]\n"
     ]
    }
   ],
   "source": [
    "print(extractFeatureVector(df_train_norm.iloc[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wenn Sie einen nieder-dimensionalen Merkmalsraum, bspw. zwei-dimensional, gewählt haben, lässt sich dieser sehr komfortabel visualisieren. Zum Beispiel:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./Figures/titanic-nieder-dimensional.png\" alt=\"drawing\" style=\"width:400px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementierung\n",
    "Die Implementierung erfolgt innerhalb der Klasse <b>KNN</b>. Im folgenden werden die einzelnen Methoden und deren Funktionsweise kurz vorgestellt. <br>\n",
    "\n",
    "\n",
    "### Konstruktor\n",
    "Das KNN-Objekt wird mit dem Wert <b>k</b> initialisiert. Dieser bestimmt die Anzahl der zu betrachtenden Nachbarn. Wählen Sie k=3 als Wert.\n",
    "\n",
    "\n",
    "### distance()-Methode:\n",
    "In dieser Methode gilt es eine Funktion zu implementieren, welche die Ähnlichkeit zweier Merkmalsvektoren vergleicht. Diese Methode soll die Ähnlichkeit der zwei Merkmalsvektoren, welche als Methoden-Parameter übergeben werden, bestimmen. Wählen Sie hierbei die aus der Vorlesung bekannten Distanz-Funktionen wie bspw. *Euklidische Distanz*, *Manhatten Distanz*, *Minkovski Distanz* etc. <br>\n",
    "\n",
    "<b>Auch hier gilt</b>: Implementieren Sie die Funktion eigenständig, eine Standard-Funktion aus einem Framework ist nicht zulässig, wie bspw. *sklearn.metrics.pairwise.euclidean_distances*. Zum Testen Ihrer Implementierung können Sie diese Funktionen nutzen.\n",
    "\n",
    "\n",
    "### fit()-Methode:\n",
    "Als Methoden-Parameter dient der normierte Trainingsdatensatz. In dieser Methode soll das Modell anhand der Trainingsdaten gebildet werden mit dem entsprechenden zuvor definierten Merkmalsvektor. <br>\n",
    "Stellen Sie sicher, dass in der Liste <b>self.trainData</b> die Merkmalsvektoren aus dem Trainingsdatensatz enthalten sind. <br>\n",
    "Stellen sie sicher, dass in der Liste <b>self.trainLabel</b> die Zielwerte des Merkmals *survived* aus dem Trainingsdatensatz enthalten sind.\n",
    "\n",
    "\n",
    "### predict()-Methode:\n",
    "Als Methoden-Parameter dient ein Merkmalsvektor. Implementieren Sie den in der Vorlesung besprochenen Algorithmus für den KNN-Klassifikator. Der Rückgabewert der Methode ist die entsprechende Mehrheits-Entscheidung."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN(object):\n",
    "    trainLabel = None\n",
    "    trainLabel = None\n",
    "    k = 1\n",
    "    distances = []\n",
    "    \n",
    "    def __init__(self, k):\n",
    "        self.k = k\n",
    "\n",
    "    #annahme das v1 und v2 dieselbe form haben\n",
    "    # sqrt(dot(x, x) - 2 * dot(x, y) + dot(y, y))\n",
    "    def distance(self, vector1, vector2 ):\n",
    "\n",
    "#         i1 = np.array(vector1)\n",
    "#         i2 = np.array(vector2)\n",
    "#         return np.linalg.norm(i1 - i2)\n",
    "#         return ( np.sqrt(vector1.dot(vector1) - (2* vector1.dot(vector2)) + vector2.dot(vector2)) )\n",
    "\n",
    "#         manhattan distance \n",
    "#         return sum(abs(e1-e2) for e1, e2 in zip(vector1, vector2))\n",
    "    \n",
    "\n",
    "#        minkowski distance\n",
    "         p = 1\n",
    "         return sum(abs(e1-e2)**p for e1, e2 in zip(vector1, vector2))**(1/p)\n",
    "    \n",
    "    \n",
    "    def fit(self, data, label):\n",
    "        self.trainData = data\n",
    "        self.trainLabel = label\n",
    "       \n",
    "        \n",
    "\n",
    "    def predict(self, x):\n",
    "        #todo das funktioniert nicht, weil dabei die labels nicht ebrücksichtig werden\n",
    "        for idx, trainSample in enumerate(self.trainData):\n",
    "            dist = self.distance(trainSample, x)\n",
    "            self.distances.append((trainSample, dist, self.trainLabel[idx]))\n",
    "        self.distances.sort(key= lambda x: x[1]) #sort for minimal distance\n",
    "        return self.distances[:self.k]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training und Test des Algorithmus\n",
    "\n",
    "Führen die Modellbildung (\"Training\") anhand der KNN-Klasse und der <b>fit()</b>-Methode durch. <br>\n",
    "Die <b>predict()</b>-Methode soll einen Merkmalsvektor $\\vec x_q$  auf die entsprechende Klassenzugehörigkeit $l \\in \\{0,1\\}$ abbilden. <br>\n",
    "Testen Sie die <b>predict()</b>-Methode mit den von ihnen gewählten Merkmalsvektoren ( _Hinweis_ : Einsatz der <b>extractFeatureVector()</b>-Methode) aus dem normierten Testdatensatz. Ermitteln sie hierzu die Korreklassifizierungsrate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "#init\n",
    "data = []\n",
    "labels = []\n",
    "l_train = len(df_train_norm)\n",
    "i = 0\n",
    "while i < l_train:\n",
    "    data.append(extractFeatureVector(df_train_norm.iloc[i]))\n",
    "    labels.append(df_train_norm.loc[i, 'Survived'])\n",
    "    i += 1\n",
    "train_data = np.array(data)\n",
    "train_label = np.array(labels)\n",
    "\n",
    "knn = KNN(3)\n",
    "knn.fit(train_data, train_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True Positives: 0\n",
      "True Negatives: 486\n",
      "False Positives: 0\n",
      "False Negatives: 300\n",
      "Accurency: 0.618321\n"
     ]
    }
   ],
   "source": [
    "##test\n",
    "l_test = len(df_test_norm)\n",
    "i = 0\n",
    "tp = 0\n",
    "fp = 0\n",
    "fn = 0\n",
    "tn = 0\n",
    "\n",
    "while i < l_test:\n",
    "    row = df_test_norm.iloc[i]\n",
    "    label = int(df_test_norm.loc[i, 'Survived'])\n",
    "    sortedNeighbors = knn.predict(extractFeatureVector(row))\n",
    "  \n",
    "\n",
    "    for neighbor in sortedNeighbors:\n",
    "        if label ==  neighbor[2]:\n",
    "            if label == 1:\n",
    "                tp +=1\n",
    "            else:\n",
    "                tn += 1\n",
    "\n",
    "        else: \n",
    "            if label == 1:\n",
    "                fn +=1\n",
    "            else:\n",
    "                fp += 1\n",
    "    i+=1\n",
    "#get acc           \n",
    "print(\"True Positives: %d\" %tp)   \n",
    "print(\"True Negatives: %d\" %tn)\n",
    "\n",
    "print(\"False Positives: %d\" %fp)\n",
    "print(\"False Negatives: %d\" %fn)\n",
    "\n",
    "acc = (tp + tn) / (tp + tn + fp + fn)\n",
    "print(\"Accurency: %f\" %acc)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weitere Evaluation\n",
    "Untersuchen Sie wie sich die Klassifikationsleistung in Abhängigkeit von verschiedenen Änhlichkeitsmaßen bzw. Merkmalsvektoren verhält. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Euclidian Distance\n",
    "### Nur Geschlecht\n",
    "True Positives: 0\n",
    "True Negatives: 486\n",
    "False Positives: 0\n",
    "False Negatives: 300\n",
    "Accurency: 0.618321\n",
    "    \n",
    "### Pclass, Sex\n",
    "True Positives: 0\n",
    "True Negatives: 486\n",
    "False Positives: 0\n",
    "False Negatives: 300\n",
    "Accurency: 0.618321\n",
    "\n",
    "### Age, Sex\n",
    "True Positives: 0\n",
    "True Negatives: 486\n",
    "False Positives: 0\n",
    "False Negatives: 300\n",
    "Accurency: 0.618321\n",
    "\n",
    "\n",
    "### Pclass, Sex, Age\n",
    "True Positives: 95\n",
    "True Negatives: 334\n",
    "False Positives: 152\n",
    "False Negatives: 205\n",
    "Accurency: 0.545802\n",
    "\n",
    "\n",
    "### Age, Sex, Pclass, Fare\n",
    "True Positives: 3\n",
    "True Negatives: 483\n",
    "False Positives: 3\n",
    "False Negatives: 297\n",
    "Accurency: 0.618321\n",
    "\n",
    "Mit Minkowski Distance p = 2\n",
    "True Positives: 3\n",
    "True Negatives: 483\n",
    "False Positives: 3\n",
    "False Negatives: 297\n",
    "Accurency: 0.618321\n",
    "\n",
    "## City Block Distance\n",
    "\n",
    "### Nur Geschlecht\n",
    "True Positives: 0\n",
    "True Negatives: 486\n",
    "False Positives: 0\n",
    "False Negatives: 300\n",
    "Accurency: 0.618321\n",
    "\n",
    "\n",
    "### Pclass, Sex, Age\n",
    "True Positives: 95\n",
    "True Negatives: 335\n",
    "False Positives: 151\n",
    "False Negatives: 205\n",
    "Accurency: 0.547074\n",
    "\n",
    "### Age, Sex, Pclass, Fare\n",
    "True Positives: 1\n",
    "True Negatives: 485\n",
    "False Positives: 1\n",
    "False Negatives: 299\n",
    "Accurency: 0.618321\n",
    "\n",
    "## Fazit\n",
    "Klassifikationsleitung bleibt gleich unabhänig des Distanzmaß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
